import asyncio
import os
import json
from twikit import Client
from twikit.errors import TooManyRequests
from dotenv import load_dotenv
import time
from datetime import datetime

# AI å…³é”®è¯å®šä¹‰
AI_KEYWORDS = {
    'en': [
        # æ ¸å¿ƒæ¦‚å¿µ
        'AI', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 
        'ML', 'DL', 'Neural Network', 'Transformer',
        
        # å¤§æ¨¡å‹ç›¸å…³
        'LLM', 'Large Language Model', 'GPT', 'Claude', 'Gemini', 'Grok',
        'ChatGPT', 'DeepSeek', 'Llama', 'Mistral', 'OpenAI', 'Anthropic',
        'Codex',
        
        # æŠ€æœ¯é¢†åŸŸ
        'NLP', 'Natural Language Processing', 'Computer Vision', 'CV',
        'Agent', 'AI Agent', 'Robotics', 'Reinforcement Learning',
        'Generative AI', 'Gen AI', 'AGI', 'Prompt Engineering',
        
        # å…¬å¸/äº§å“
        'Google AI', 'Meta AI', 'DeepMind', 'Stability AI', 
        'Midjourney', 'Stable Diffusion', 'DALL-E',
        
        # åº”ç”¨
        'Data Science', 'MLOps', 'AI Research', 'AI Safety',
        'Autonomous', 'Automation'
    ],
    'zh': [
        'äººå·¥æ™ºèƒ½', 'AI', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'å¤§æ¨¡å‹', 
        'å¤§è¯­è¨€æ¨¡å‹', 'LLM', 'GPT', 'Claude', 'ChatGPT',
        'é€šä¹‰', 'æ–‡å¿ƒ', 'æ™ºè°±', 'ç™¾å·', 'æœˆä¹‹æš—é¢',
        'æ•°æ®ç§‘å­¦', 'è‡ªç„¶è¯­è¨€å¤„ç†', 'è®¡ç®—æœºè§†è§‰', 
        'å¼ºåŒ–å­¦ä¹ ', 'ç”Ÿæˆå¼AI', 'Agent', 'æ™ºèƒ½ä½“'
    ],
    'ja': [
        'AI', 'äººå·¥çŸ¥èƒ½', 'æ©Ÿæ¢°å­¦ç¿’', 'æ·±å±¤å­¦ç¿’', 
        'LLM', 'GPT', 'ChatGPT', 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹'
    ]
}

# æœ€å°ç²‰ä¸æ•°è¦æ±‚
MIN_FOLLOWERS = 10000


async def handle_rate_limit(e: TooManyRequests, context: str = "") -> None:
    """
    å¤„ç†é€Ÿç‡é™åˆ¶ï¼Œæ™ºèƒ½è®¡ç®—ä¼‘çœ æ—¶é—´
    
    å‚æ•°:
        e: TooManyRequests å¼‚å¸¸å¯¹è±¡
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”¨äºæ—¥å¿—è¾“å‡º
    """
    if e.rate_limit_reset:
        reset_time = datetime.fromtimestamp(e.rate_limit_reset)
        current_time = datetime.now()
        sleep_seconds = (reset_time - current_time).total_seconds() + 10  # åŠ  10 ç§’ç¼“å†²
        sleep_seconds = max(sleep_seconds, 60)  # è‡³å°‘ä¼‘çœ  60 ç§’
        
        print(f"  âš ï¸  é‡åˆ°é€Ÿç‡é™åˆ¶ (429)")
        if context:
            print(f"  {context}")
        print(f"  å½“å‰æ—¶é—´: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"  é‡ç½®æ—¶é—´: {reset_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"  ä¼‘çœ  {int(sleep_seconds)} ç§’ ({int(sleep_seconds/60)} åˆ†é’Ÿ)...")
    else:
        sleep_seconds = 3600  # é»˜è®¤ 1 å°æ—¶
        print(f"  âš ï¸  é‡åˆ°é€Ÿç‡é™åˆ¶ (429)ï¼Œæœªè·å–åˆ°é‡ç½®æ—¶é—´ï¼Œé»˜è®¤ä¼‘çœ  1 å°æ—¶...")
        if context:
            print(f"  {context}")
        print(f"  å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    await asyncio.sleep(sleep_seconds)
    print(f"  ä¼‘çœ ç»“æŸï¼Œç»§ç»­æ‰§è¡Œ... {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def is_ai_related_user(user, keywords: dict) -> bool:
    """
    æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸º AI ç›¸å…³ç”¨æˆ·
    """
    # æ£€æŸ¥ç²‰ä¸æ•°
    if user.followers_count < MIN_FOLLOWERS:
        return False
    
    # æ£€æŸ¥æè¿°æ˜¯å¦ä¸ºç©º
    if not user.description:
        return False
    
    # è½¬å°å†™è¿›è¡Œå…³é”®è¯åŒ¹é…
    description_lower = user.description.lower()
    
    # æ£€æŸ¥æ‰€æœ‰è¯­è¨€çš„å…³é”®è¯
    for lang, keyword_list in keywords.items():
        for keyword in keyword_list:
            if keyword.lower() in description_lower:
                return True
    
    return False


async def get_user_following(client, user_id: str, max_count: int = 200) -> list:
    """
    è·å–ç”¨æˆ·çš„å…³æ³¨åˆ—è¡¨ï¼Œæ”¯æŒåˆ†é¡µ
    
    å‚æ•°:
        client: Twitter å®¢æˆ·ç«¯
        user_id: ç”¨æˆ·ID
        max_count: æœ€å¤šè·å–å¤šå°‘ä¸ªå…³æ³¨ç”¨æˆ·ï¼ˆé¿å…è¿‡åº¦è¯·æ±‚ï¼‰
    
    è¿”å›:
        å…³æ³¨ç”¨æˆ·å¯¹è±¡åˆ—è¡¨
    """
    all_following = []
    
    try:
        # è·å–ç¬¬ä¸€é¡µï¼ˆæ¯é¡µ20ä¸ªï¼‰
        following_result = await client.get_user_following(user_id, count=200)
        
        # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
        all_following.extend(following_result)
        
        # åˆ†é¡µè·å–æ›´å¤šæ•°æ®
        pages_fetched = 1
        max_pages = (max_count // 20) + 1  # è®¡ç®—éœ€è¦è·å–å¤šå°‘é¡µ
        
        while len(all_following) < max_count and pages_fetched < max_pages:
            try:
                # è·å–ä¸‹ä¸€é¡µ
                following_result = await following_result.next()
                
                if not following_result:  # æ²¡æœ‰æ›´å¤šæ•°æ®
                    break
                
                all_following.extend(following_result)
                pages_fetched += 1
                
                # å»¶è¿Ÿé¿å…é™æµ
                await asyncio.sleep(1)
            
            except TooManyRequests as e:
                await handle_rate_limit(e, "åˆ†é¡µè·å–å…³æ³¨åˆ—è¡¨æ—¶")
            except Exception as e:
                print(f"  åˆ†é¡µè·å–å‡ºé”™: {e}")
                break
        
        # æˆªå–åˆ°æŒ‡å®šæ•°é‡
        return all_following[:max_count]
    
    except TooManyRequests as e:
        await handle_rate_limit(e, "è·å–ç”¨æˆ·å…³æ³¨åˆ—è¡¨æ—¶")
        return []
    except Exception as e:
        print(f"  è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥: {e}")
        return []


def extract_user_info(user, depth: int, source: str) -> dict:
    """
    ä» User å¯¹è±¡æå–éœ€è¦çš„ä¿¡æ¯
    """
    return {
        'screen_name': user.screen_name,
        'name': user.name,
        'id': user.id,
        'description': user.description,
        'followers_count': user.followers_count,
        'following_count': user.following_count,
        'verified': user.verified,
        'profile_url': f"https://x.com/{user.screen_name}",
        'discovered_at_depth': depth,
        'discovered_from': source
    }


def save_progress(progress: dict, filename: str):
    """
    ä¿å­˜è¿›åº¦åˆ°æ–‡ä»¶
    """
    # å°† set è½¬æ¢ä¸º list ä»¥ä¾¿ JSON åºåˆ—åŒ–
    progress_copy = progress.copy()
    progress_copy['processed_users'] = list(progress['processed_users'])
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(progress_copy, f, ensure_ascii=False, indent=2)
    
    print(f"  [è¿›åº¦å·²ä¿å­˜] æ·±åº¦:{progress['current_depth']}, "
          f"é˜Ÿåˆ—ä½ç½®:{progress.get('current_queue_index', 0)}/{len(progress.get('queue', []))}")


def load_progress(filename: str) -> dict:
    """
    ä»æ–‡ä»¶åŠ è½½è¿›åº¦
    """
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            progress = json.load(f)
            progress['processed_users'] = set(progress['processed_users'])
            # ç¡®ä¿æœ‰ current_queue_index å­—æ®µ
            if 'current_queue_index' not in progress:
                progress['current_queue_index'] = 0
            return progress
    except FileNotFoundError:
        return None


def load_seed_users(filename: str) -> list:
    """
    åŠ è½½ç§å­ç”¨æˆ·åˆ—è¡¨
    """
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('seed_users', data) if isinstance(data, dict) else data
    except FileNotFoundError:
        return []


async def collect_ai_users(client, seed_users: list, max_depth: int = 5, resume_progress: dict = None) -> dict:
    """
    æ”¶é›† AI ç›¸å…³ç”¨æˆ·ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
    """
    # å¦‚æœæœ‰æ¢å¤è¿›åº¦ï¼Œåˆ™ä»è¿›åº¦æ¢å¤
    if resume_progress:
        ai_users = resume_progress['ai_users']
        processed_users = resume_progress['processed_users']
        start_depth = resume_progress['current_depth']
        current_queue = resume_progress['queue']
        start_index = resume_progress.get('current_queue_index', 0)
        
        print(f"\nğŸ”„ ä»ä¸Šæ¬¡è¿›åº¦æ¢å¤:")
        print(f"   æ·±åº¦: ç¬¬ {start_depth + 1} å±‚")
        print(f"   å·²æ‰¾åˆ°: {len(ai_users)} ä¸ª AI ç”¨æˆ·")
        print(f"   é˜Ÿåˆ—ä½ç½®: {start_index}/{len(current_queue)}")
    else:
        # å…¨æ–°å¼€å§‹
        ai_users = {}
        processed_users = set()
        start_depth = 0
        current_queue = seed_users.copy()
        start_index = 0
    
    # æŒ‰æ·±åº¦éå†
    for depth in range(start_depth, max_depth):
        print(f"\n=== å¼€å§‹å¤„ç†ç¬¬ {depth + 1} å±‚ ===")
        print(f"å¾…å¤„ç†ç”¨æˆ·æ•°: {len(current_queue)}")
        
        # å¦‚æœæ˜¯æ¢å¤çš„å±‚ï¼Œä» start_index å¼€å§‹ï¼›å¦åˆ™ä» 0 å¼€å§‹
        queue_start = start_index if depth == start_depth else 0
        
        next_queue = []
        
        # å¤„ç†å½“å‰å±‚çš„æ¯ä¸ªç”¨æˆ·ï¼ˆä»æŒ‡å®šä½ç½®å¼€å§‹ï¼‰
        for idx in range(queue_start, len(current_queue)):
            screen_name = current_queue[idx]
            # è·³è¿‡å·²å¤„ç†ç”¨æˆ·
            if screen_name in processed_users:
                continue
            
            # æ ‡è®°ä¸ºå·²å¤„ç†
            processed_users.add(screen_name)
            
            try:
                # è·å–ç”¨æˆ·ä¿¡æ¯
                user = await client.get_user_by_screen_name(screen_name)
                
                # æ£€æŸ¥æ˜¯å¦ç¬¦åˆ AI ç”¨æˆ·æ ‡å‡†
                if is_ai_related_user(user, AI_KEYWORDS):
                    # ä¿å­˜ç”¨æˆ·ä¿¡æ¯
                    user_info = extract_user_info(user, depth, 'seed' if depth == 0 else 'following')
                    ai_users[screen_name] = user_info
                    print(f"âœ“ æ‰¾åˆ° AI ç”¨æˆ·: @{screen_name} (ç²‰ä¸: {user.followers_count}, å…³æ³¨: {user.following_count})")
                    
                    # å¦‚æœå…³æ³¨æ•°è¶…è¿‡ 500ï¼Œè·³è¿‡è·å–å…³æ³¨åˆ—è¡¨
                    if user.following_count > 500:
                        print(f"  âš ï¸  å…³æ³¨æ•° {user.following_count} è¶…è¿‡ 500ï¼Œè·³è¿‡è·å–å…³æ³¨åˆ—è¡¨")
                    else:
                        # è·å–è¯¥ç”¨æˆ·çš„å…³æ³¨åˆ—è¡¨
                        following_list = await get_user_following(client, user.id, max_count=user.followers_count)
                        print(f"  è·å–åˆ° {len(following_list)} ä¸ªå…³æ³¨ç”¨æˆ·")
                        
                        # å°†å…³æ³¨åˆ—è¡¨åŠ å…¥ä¸‹ä¸€å±‚é˜Ÿåˆ—
                        for followed_user in following_list:
                            if followed_user.screen_name not in processed_users:
                                next_queue.append(followed_user.screen_name)
                else:
                    print(f"âœ— è·³è¿‡: @{screen_name}")
                
                # å»¶è¿Ÿé¿å…é™æµ
                await asyncio.sleep(10)
                
                # æ¯å¤„ç† 1 ä¸ªç”¨æˆ·ä¿å­˜ä¸€æ¬¡è¿›åº¦
                progress = {
                    'current_depth': depth,
                    'current_queue_index': idx + 1,  # è®°å½•ä¸‹ä¸€ä¸ªè¦å¤„ç†çš„ä½ç½®
                    'processed_users': processed_users,
                    'ai_users': ai_users,
                    'queue': current_queue  # ä¿å­˜å½“å‰å±‚é˜Ÿåˆ—
                }
                save_progress(progress, 'progress.json')
            
            except TooManyRequests as e:
                # ä¿å­˜å½“å‰è¿›åº¦
                progress = {
                    'current_depth': depth,
                    'current_queue_index': idx,  # ä¿æŒå½“å‰ä½ç½®ï¼Œä¸‹æ¬¡ç»§ç»­å¤„ç†è¿™ä¸ªç”¨æˆ·
                    'processed_users': processed_users,
                    'ai_users': ai_users,
                    'queue': current_queue
                }
                save_progress(progress, 'progress.json')
                
                # å¤„ç†é€Ÿç‡é™åˆ¶
                context = f"å¤„ç†è¿›åº¦: ç¬¬ {depth + 1} å±‚, ä½ç½® {idx + 1}/{len(current_queue)}"
                await handle_rate_limit(e, context)
                
                # é‡è¯•å½“å‰ç”¨æˆ·ï¼ˆä¸å¢åŠ  idxï¼Œå¾ªç¯ä¼šç»§ç»­ï¼‰
                continue
                
            except Exception as e:
                print(f"å¤„ç†ç”¨æˆ· @{screen_name} æ—¶å‡ºé”™: {e}")
                continue
        
        # å»é‡ä¸‹ä¸€å±‚é˜Ÿåˆ—
        current_queue = list(set(next_queue))
        
        # é‡ç½®ç´¢å¼•ï¼ˆä¸‹ä¸€å±‚ä»å¤´å¼€å§‹ï¼‰
        start_index = 0
        
        # ä¿å­˜æœ¬å±‚å®Œæˆçš„è¿›åº¦
        progress = {
            'current_depth': depth + 1,  # ä¸‹ä¸€å±‚æ·±åº¦
            'current_queue_index': 0,     # ä¸‹ä¸€å±‚ä»å¤´å¼€å§‹
            'processed_users': processed_users,
            'ai_users': ai_users,
            'queue': current_queue
        }
        save_progress(progress, 'progress.json')
        
        print(f"ç¬¬ {depth + 1} å±‚å®Œæˆï¼Œæ‰¾åˆ° {len(ai_users)} ä¸ª AI ç”¨æˆ·")
    
    return ai_users


async def main():
    """
    ä¸»å…¥å£å‡½æ•°
    """
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = Client('en-US')
    client.set_cookies({
        'auth_token': os.getenv('TWITTER_AUTH_TOKEN'),
        'ct0': os.getenv('TWITTER_CT0'),
        'twid': os.getenv('TWITTER_TWID'),
        'kdt': os.getenv('TWITTER_KDT')
    })
    
    # éªŒè¯ç™»å½•
    me = await client.user()
    print(f"å½“å‰ç™»å½•ç”¨æˆ·: {me.name}\n")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¿›åº¦æ–‡ä»¶
    progress = load_progress('progress.json')
    
    if progress:
        print("=" * 60)
        print("å‘ç°ä¸Šæ¬¡æœªå®Œæˆçš„è¿›åº¦ï¼")
        print(f"  æ·±åº¦: ç¬¬ {progress['current_depth'] + 1} å±‚")
        print(f"  å·²æ‰¾åˆ°: {len(progress['ai_users'])} ä¸ª AI ç”¨æˆ·")
        print(f"  é˜Ÿåˆ—å‰©ä½™: {len(progress['queue'])} ä¸ªç”¨æˆ·")
        print(f"  å½“å‰ä½ç½®: {progress.get('current_queue_index', 0)}/{len(progress['queue'])}")
        print("=" * 60)
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        response = input("\næ˜¯å¦ä»ä¸Šæ¬¡ä½ç½®ç»§ç»­ï¼Ÿ(y/nï¼Œç›´æ¥å›è½¦é»˜è®¤ y): ").strip().lower()
        
        if response in ['', 'y', 'yes']:
            print("\nâœ… ä»ä¸Šæ¬¡è¿›åº¦ç»§ç»­...\n")
            # ä»è¿›åº¦æ¢å¤
            ai_users = await collect_ai_users(
                client, 
                seed_users=[], 
                max_depth=3, 
                resume_progress=progress
            )
        else:
            print("\nâŒ æ”¾å¼ƒä¸Šæ¬¡è¿›åº¦ï¼Œé‡æ–°å¼€å§‹...\n")
            # åˆ é™¤æ—§è¿›åº¦æ–‡ä»¶
            import os as os_module
            if os_module.path.exists('progress.json'):
                os_module.remove('progress.json')
            
            # è¯»å–ç§å­ç”¨æˆ·ï¼Œé‡æ–°å¼€å§‹
            seed_users = load_seed_users('seed_users.json')
            if not seed_users:
                seed_users = ['karpathy', 'AndrewYNg', 'goodfellow_ian']
                print(f"ä½¿ç”¨é»˜è®¤ç§å­ç”¨æˆ·: {seed_users}")
            
            ai_users = await collect_ai_users(client, seed_users, max_depth=3)
    else:
        # æ²¡æœ‰è¿›åº¦æ–‡ä»¶ï¼Œå…¨æ–°å¼€å§‹
        print("ğŸ“‹ å¼€å§‹å…¨æ–°çš„æ”¶é›†ä»»åŠ¡...\n")
        seed_users = load_seed_users('seed_users.json')
        if not seed_users:
            seed_users = ['karpathy', 'AndrewYNg', 'goodfellow_ian']
            print(f"ä½¿ç”¨é»˜è®¤ç§å­ç”¨æˆ·: {seed_users}")
        
        ai_users = await collect_ai_users(client, seed_users, max_depth=3)
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    with open('ai_users_result.json', 'w', encoding='utf-8') as f:
        json.dump(ai_users, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ‰ å®Œæˆï¼å…±æ‰¾åˆ° {len(ai_users)} ä¸ª AI é¢†åŸŸç”¨æˆ·")
    print(f"ç»“æœå·²ä¿å­˜è‡³: ai_users_result.json")
    
    # æ¸…ç†è¿›åº¦æ–‡ä»¶
    import os as os_module
    if os_module.path.exists('progress.json'):
        os_module.remove('progress.json')
        print("âœ“ è¿›åº¦æ–‡ä»¶å·²æ¸…ç†")


if __name__ == '__main__':
    asyncio.run(main())

